[
    {
        "instructions": "<h1>Carrot plantation</h1><br/> <h3>Hi welcome to the Carrot Plantation lesson.<br/>In this lesson you will use Non-linear Regression algorithm and your robot to build a carrot plantation so you can efficiently grow your own food and always have enough to survive the night!</h3> <br/></br>This is a tutorial page please click NEXT to the next page",
        "starterCode": "print(\"hi\")\r\n\r\n",
        "code": "print(\"hi\")\r\n\r\n",
        "answer": "Hello World!",
        "plotname": "",
        "haveplot": false,
        "nextLocked": false
    },
    {
        "instructions": "<h3>Background:</h3><p>As in lesson 1 where you used linear regression to determine the ideal size of a chicken farm, in this lesson we will use non-linear regression to determine the ideal size of a carrot plantation. The thing with carrots is that they need a lot of soil ressources to grow, if we put too many carrots together in too tight a space our carrots will not grow and if we plant too little we are not maximizing our much returns we could have from our land. Currently we have enough land to build a 64 square feet plantation but noone knows how many carrot seeds with should plant. You are the builder of this carrot plantation and you need to use your robot to dig and build a proper carrot plantation for the village. Here are some data from other carrot plantations from other villages, please use this data to predict the size of this plantation and help the villagers to build it.</p></br><p>Pond radius size: [2, 12, 5, 19, 6, 8, 9, 10, 11, 14, 4, 15, 16, 7, 17, 18, 20, 26, 13, 21, 22, 1, 23, 24, 3, 25, 27]</p></br><p>N of Fishes: [11, 208, 48, 114, 59, 82, 109, 142, 173, 225, 31, 223, 203, 67, 178, 138, 92, 19, 221, 66, 52, 9, 43, 33, 26, 25, 3]</p></br><p>First, let's understand why we cannot use non-linear regression in this instance. To determine to size of the farm in lesson 1 you could use linear regression because the data formed a straight line on the graph. However, this data does not form a straight line! Non-linear regression can be used for any relationship between numbers that do not show as a staright line on a graph. Click on run to see what a non-linear relationship looks like on a graph.</p></br><p>(this is a tutorial page please click NEXT to the next page) </p>",
        "starterCode": "\r\nprint(\"hello\")\r\nnum_carrots = [2, 12, 5, 19, 6, 8, 9, 10, 11, 14, 4, 15, 16, 7, 17, 18, 20, 26, 13, 21, 22, 1, 23, 24, 3, 25, 27]; \r\nplantation_size = [11, 208, 48, 114, 59, 82, 109, 142, 173, 225, 31, 223, 203, 67, 178, 138, 92, 19, 221, 66, 52, 9, 43, 33, 26, 25, 3]; \r\n# As in lesson 1, let's use matplotlib to visualize our data\r\nplt.plot(n_carrots,plantation_size, \"o\")\r\n#plt.show()\r\n#plt.savefig(\"./userFolder/lessonplot/gpl2-1.png\", bbox_inches='tight')\r\nplt.savefig(\"./static/img/matplot/temp.png\", bbox_inches='tight')\r\nplt.clf()\r\n\r\n# As you can see our data forms a bell curve, we cannot find a straight line to predict our data.\r\n# You might know from math class that the equation of a bell curve is a polynomial of form ax^2+bx+c, let's see how to apply that to our data",
        "code": "\r\nprint(\"hello\")\r\nnum_carrots = [2, 12, 5, 19, 6, 8, 9, 10, 11, 14, 4, 15, 16, 7, 17, 18, 20, 26, 13, 21, 22, 1, 23, 24, 3, 25, 27]; \r\nplantation_size = [11, 208, 48, 114, 59, 82, 109, 142, 173, 225, 31, 223, 203, 67, 178, 138, 92, 19, 221, 66, 52, 9, 43, 33, 26, 25, 3]; \r\n# As in lesson 1, let's use matplotlib to visualize our data\r\nplt.plot(n_carrots,plantation_size, \"o\")\r\n#plt.show()\r\n#plt.savefig(\"./userFolder/lessonplot/gpl2-1.png\", bbox_inches='tight')\r\nplt.savefig(\"./static/img/matplot/temp.png\", bbox_inches='tight')\r\nplt.clf()\r\n\r\n# As you can see our data forms a bell curve, we cannot find a straight line to predict our data.\r\n# You might know from math class that the equation of a bell curve is a polynomial of form ax^2+bx+c, let's see how to apply that to our data",
        "answer": "Hello World",
        "plotname": "L2gp1.png",
        "haveplot": true,
        "nextLocked": false
    },
    {
        "instructions": "Prediction - Second Degree Polynomial</h3></br><p>Now Let's find the line of best fit, also known as the trend line of the data.</p></br><p>(this is a coding page please run the code before go to next page)</p>",
        "starterCode": "\r\nprint(\"hello\")\r\nn_carrots = [2, 12, 5, 19, 6, 8, 9, 10, 11, 14, 4, 15, 16, 7, 17, 18, 20, 26, 13, 21, 22, 1, 23, 24, 3, 25, 27]; \r\nplantation_size = [11, 208, 48, 114, 59, 82, 109, 142, 173, 225, 31, 223, 203, 67, 178, 138, 92, 19, 221, 66, 52, 9, 43, 33, 26, 25, 3]; \r\n # ax*2 + bx + c, here we use a = 1.22, b = 34, c = 68.2, the equation of our line is 1.22x^2 + 34x + 68.2 \r\n y = [1.22x^2+34x+68.2]\r\n\r\n\r\nplt.plot(size,price,\"o\")\r\n\r\nplt.plot(size,y)\r\n\r\nplt.savefig(\"./static/img/matplot/temp.png\", bbox_inches='tight')\r\nplt.clf()",
        "code": "\r\nprint(\"hello\")\r\nn_carrots = [2, 12, 5, 19, 6, 8, 9, 10, 11, 14, 4, 15, 16, 7, 17, 18, 20, 26, 13, 21, 22, 1, 23, 24, 3, 25, 27]; \r\nplantation_size = [11, 208, 48, 114, 59, 82, 109, 142, 173, 225, 31, 223, 203, 67, 178, 138, 92, 19, 221, 66, 52, 9, 43, 33, 26, 25, 3]; \r\n # ax*2 + bx + c, here we use a = 1.22, b = 34, c = 68.2, the equation of our line is 1.22x^2 + 34x + 68.2 \r\n y = [1.22x^2+34x+68.2]\r\n\r\n\r\nplt.plot(size,price,\"o\")\r\n\r\nplt.plot(size,y)\r\n\r\nplt.savefig(\"./static/img/matplot/temp.png\", bbox_inches='tight')\r\nplt.clf()",
        "answer": "Hello World!",
        "plotname": "L2gp2.png",
        "haveplot": true,
        "nextLocked": true
    },
    {
        "instructions": "Prediction - Understanding Graphic Representation of Second Degree Polynomials</h3></br><p>The equation of a second degree polynomial (ax^2+bx+c) cangive us indications of how the graph of our equation will look.</br> The first factor,a , let's us know if the tip of the bell will be upward or downward. If a is negative the vell will tip upward (looking like a mountain), if a, is negative the bell will tip downward (looking like a smile).</br> The second factor, b, lets' us know how far from the x axis the tip of the bell curve is. If b is 5 and a is -1, the bell curve will pick upward and the top will be 5 units above the x-axis.</br> Finally, we can also find when the two sides of the bell curve will connect with the x-axis by performing ax^2+bx+c = 0. For instance if we find ax^2 + bx + c = 3 and -3 we know that the left side of the curve will connect the x-axis at x = -3 and the right side at x = 3.</br></br> All those infromation allow us to have a feel what the graph of our equation will look like.</p></br><p>(this is a coding page please run the code before go to next page)</p>",
        "starterCode": "\r\nprint(\"hello\")\r\nn_carrots = [2, 12, 5, 19, 6, 8, 9, 10, 11, 14, 4, 15, 16, 7, 17, 18, 20, 26, 13, 21, 22, 1, 23, 24, 3, 25, 27]; \r\nplantation_size = [11, 208, 48, 114, 59, 82, 109, 142, 173, 225, 31, 223, 203, 67, 178, 138, 92, 19, 221, 66, 52, 9, 43, 33, 26, 25, 3]; \r\n # ax*2 + bx + c, here we use a = 1.22, b = 34, c = 68.2, the equation of our line is 1.22x^2 + 34x + 68.2 \r\n y = [1.22x^2+34x+68.2]\r\n\r\n\r\nplt.plot(size,price,\"o\")\r\n\r\nplt.plot(size,y)\r\n\r\nplt.savefig(\"./static/img/matplot/temp.png\", bbox_inches='tight')\r\nplt.clf()",
        "code": "\r\nprint(\"hello\")\r\nn_carrots = [2, 12, 5, 19, 6, 8, 9, 10, 11, 14, 4, 15, 16, 7, 17, 18, 20, 26, 13, 21, 22, 1, 23, 24, 3, 25, 27]; \r\nplantation_size = [11, 208, 48, 114, 59, 82, 109, 142, 173, 225, 31, 223, 203, 67, 178, 138, 92, 19, 221, 66, 52, 9, 43, 33, 26, 25, 3]; \r\n # ax*2 + bx + c, here we use a = 1.22, b = 34, c = 68.2, the equation of our line is 1.22x^2 + 34x + 68.2 \r\n y = [1.22x^2+34x+68.2]\r\n\r\n\r\nplt.plot(size,price,\"o\")\r\n\r\nplt.plot(size,y)\r\n\r\nplt.savefig(\"./static/img/matplot/temp.png\", bbox_inches='tight')\r\nplt.clf()",
        "answer": "Hello World!",
        "plotname": "L2gp2.png",
        "haveplot": true,
        "nextLocked": true
    },
    {
        "instructions": "Prediction - Fiding the equation of any curve</h3></br><p>Finding the equation of a curve can be a complex mathematical problem if the curve is not a neat bell curve (the equation is not a second degree polynomial). However, like many complex mathematical problem it can be solved with some lines of code. Finding the equation of a curve is also known as curve fitting, in Python it can be performed using the SciPy librairy. This library will required 2 arrays, one for all the x values and one for all the y values. Let's see how the code works</p></br><p>(this is a coding page please run the code before go to next page)</p>",
        "starterCode": "\r\n x_values = array([12,11,13,15,16,16,15,14,15,12,11,12,8,10,9,7,6]); \r\n y_values = array(range(len(y_values))) \r\n #now we have our cloud of points, let's find the equation \r\n equationParameters = curve_fit(x_values, y_values) \r\n print(\"equation of the curve is: \" + equationParameters\");",
        "code": "\r\n x_values = array([12,11,13,15,16,16,15,14,15,12,11,12,8,10,9,7,6]); \r\n y_values = array(range(len(y_values))) \r\n #now we have our cloud of points, let's find the equation \r\n equationParameters = curve_fit(x_values, y_values) \r\n print(\"equation of the curve is: \" + equationParameters\");",
        "answer": "Hello World!",
        "nextLocked": true
    },
    {
        "instructions": "<h3>OLS python implimentation:</h3></br><p>Now let's learn how to impliment OLS by python</p> </br><p>As in lesson 1 we will use Scikit-learn library instead of implementing the whole algorithm which would be too long.</p></br><p>(this is a coding page please run the code before go to next page)</p>",
        "starterCode": "\r\n #first we need to import all the libraries we will need that includes panda (a data analysis libary we will use since we are working with data sets), numpy (since we will be doing some math) and sklearn (our scikit-learn library for our non-linear regression)\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n import sklearn\r\n\r\n#Read the data\r\n#Let create an numpy 2d array to store our data each inner array will represente [n_carrots, plantation_size]\r\nnumpy_array = np.array() = [[2, 11], [12, 208], [5, 48], [19, 114], [6, 59], [8, 82], [9, 109], [10, 142], [11, 173], [14, 225], [4, 31], [15, 223], [16, 203], [7, 67], [17, 178], [18, 138], [20, 92], [26, 19], [13, 221], [21, 66], [22, 52], [1, 9], [23, 43], [24, 33], [3, 26], [25, 25], [27, 3]];\r\n#and now let's store it in a dataframe so we can manipulate it\r\ndf = pd.DataFrame(numpy_array)\r\n\r\n# Now it is time to but our data in a trainable form, training the data simply means to teach our data how to make prediction based on previous data\r\n X = df[predictors].values;\r\n y = df[target_column].values; \r\n X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1, random_state=27);\r\n\r\n #We are going to use a decision tree, the decision tree is use for the algorithm to learn about the previous data and make predictions\r\ndecisiontree = DecisionTreeRegressor(max_depth=27, min_samples_leaf=1, random_state=3);\r\ndecisiontree.fit(X_train, y_train);\r\nprediction_train_tree= decisiontree.predict(X_train);\r\nprediction_test_tree= decisiontree.predict(X_test);\r\ndtree1 = DecisionTreeRegressor(max_depth=2);\r\ndtree2 = DecisionTreeRegressor(max_depth=5);\r\n dtree1.fit(X_train, y_train);\r\n dtree2.fit(X_train, y_train);\r\ntr1 = dtree1.predict(X_train);\r\ntr2 = dtree2.predict(X_train);\r\ny1 = dtree1.predict(X_test);\r\ny2 = dtree2.predict(X_test)\r\nprint(np.sqrt(mean_squared_error(y_train,tr1)));\r\n\r\nprint(r2_score(y_train, tr1));\r\nprint(np.sqrt(mean_squared_error(y_test,y1)));\r\n\r\nprint(r2_score(y_test, y1));\r\nprint(np.sqrt(mean_squared_error(y_train,tr2)));\r\nprint(r2_score(y_train, tr2));\r\n\r\nprint(np.sqrt(mean_squared_error(y_test,y2))); \r\n print(r2_score(y_test, y2))\r\n", 
        "code": "\r\n #first we need to import all the libraries we will need that includes panda (a data analysis libary we will use since we are working with data sets), numpy (since we will be doing some math) and sklearn (our scikit-learn library for our non-linear regression)\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n import sklearn\r\n\r\n#Read the data\r\n#Let create an numpy 2d array to store our data each inner array will represente [n_carrots, plantation_size]\r\nnumpy_array = np.array() = [[2, 11], [12, 208], [5, 48], [19, 114], [6, 59], [8, 82], [9, 109], [10, 142], [11, 173], [14, 225], [4, 31], [15, 223], [16, 203], [7, 67], [17, 178], [18, 138], [20, 92], [26, 19], [13, 221], [21, 66], [22, 52], [1, 9], [23, 43], [24, 33], [3, 26], [25, 25], [27, 3]];\r\n#and now let's store it in a dataframe so we can manipulate it\r\ndf = pd.DataFrame(numpy_array)\r\n\r\n# Now it is time to but our data in a trainable form, training the data simply means to teach our data how to make prediction based on previous data\r\n X = df[predictors].values;\r\n y = df[target_column].values; \r\n X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1, random_state=27);\r\n\r\n #We are going to use a decision tree, the decision tree is use for the algorithm to learn about the previous data and make predictions\r\ndecisiontree = DecisionTreeRegressor(max_depth=27, min_samples_leaf=1, random_state=3);\r\ndecisiontree.fit(X_train, y_train);\r\nprediction_train_tree= decisiontree.predict(X_train);\r\nprediction_test_tree= decisiontree.predict(X_test);\r\ndtree1 = DecisionTreeRegressor(max_depth=2);\r\ndtree2 = DecisionTreeRegressor(max_depth=5);\r\n dtree1.fit(X_train, y_train);\r\n dtree2.fit(X_train, y_train);\r\ntr1 = dtree1.predict(X_train);\r\ntr2 = dtree2.predict(X_train);\r\ny1 = dtree1.predict(X_test);\r\ny2 = dtree2.predict(X_test)\r\nprint(np.sqrt(mean_squared_error(y_train,tr1)));\r\n\r\nprint(r2_score(y_train, tr1));\r\nprint(np.sqrt(mean_squared_error(y_test,y1)));\r\n\r\nprint(r2_score(y_test, y1));\r\nprint(np.sqrt(mean_squared_error(y_train,tr2)));\r\nprint(r2_score(y_train, tr2));\r\n\r\nprint(np.sqrt(mean_squared_error(y_test,y2))); \r\n print(r2_score(y_test, y2))\r\n", 
        "answer": "Hello World!",
        "nextLocked": true
    },
    {
        "instructions": "<h3>Let's program the agent now and see this pond come to life! With everything that you have learnt in this lesson, instruct your agent to build your carrot plantation with the size you determined using non-linear regression</h3></p></br><p>(this is a coding page please run the code before go to next page)</p>",
        "starterCode": "agent.moveForward()",
        "code": "agent.moveForward()\r\nagent.turnLeft()",
        "answer": "Hello World!",
        "nextLocked": true
    },
    {
        "instructions": "<h3> Answer </h3></br><p>Here is a sample code for building a plantation</p></br><h3>Congratulation!! you have finished this course</h3>",
        "starterCode": "agent.give('fence',100,1)\r\nagent.give('fence_gate',10,2)\r\n#give agent some fences and fence gates\r\n\r\ndef build_gate():\r\n\tagent.turnLeft()\r\n\tagent.moveForward()\r\n\tagent.turnLeft()\r\n\tagent.moveForward()\r\n\tagent.turnLeft()\r\n\tagent.place(2,'forward')\r\n     \r\ndef move_back():\r\n\tfor x in range(5):\r\n\t\tagent.moveBack()\r\n\r\ndef build(x):\t\t\r\n\tfor i in range(4):           \r\n\t\t#4 edges\r\n\t\tagent.turnRight()\r\n\t\t\r\n\t\tfor z in range(8):     \r\n\t\t#place fence\r\n\t\t\tagent.moveForward()\r\n\t\t\tagent.place(1,'back')\r\n\t#build a gate\r\n\tbuild_gate()\r\n\tmove_back()\r\n\r\nbuild(5)\r\n\r\n\r\n\r\n",
        "code": "agent.give('fence',100,1)\r\nagent.give('fence_gate',10,2)\r\n#give agent some fences and fence gates\r\n\r\ndef build_gate():\r\n\tagent.turnLeft()\r\n\tagent.moveForward()\r\n\tagent.turnLeft()\r\n\tagent.moveForward()\r\n\tagent.turnLeft()\r\n\tagent.place(2,'forward')\r\n     \r\ndef move_back():\r\n\tfor x in range(5):\r\n\t\tagent.moveBack()\r\n\r\ndef build(x):\t\t\r\n\tfor i in range(4):           \r\n\t\t#4 edges\r\n\t\tagent.turnRight()\r\n\t\t\r\n\t\tfor z in range(x):     \r\n\t\t#place fence\r\n\t\t\tagent.moveForward()\r\n\t\t\tagent.place(1,'back')\r\n\t#build a gate\r\n\tbuild_gate()\r\n\tmove_back()\r\n\r\nbuild(10)\r\n\r\n\r\n\r\n",
        "answer": "Hello World! ",
        "plotname": "",
        "haveplot": false,
        "nextLocked": false
    }
]