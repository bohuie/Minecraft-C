{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emerald Collection Competition (K-nearest neighbors)\n",
    "\n",
    "\n",
    "#### Hi welcome to the Emerald Collection Competition lesson.\n",
    "\n",
    "#### In this lesson you will use `K-nearest neighbors (KNN)` algorithm and your agent to to collect Emerald!\n",
    "\n",
    "<img src=\"resources/Background.png\" width=800px>\n",
    "\n",
    "#### Background:\n",
    "\n",
    "Someone holds a machine learning competition in the village, and the winner could win a lot of emeralds. There are four zones in the village, only one of which is buried with emeralds, and each contestant has only one chance to dig for the treasure. The plants in each area are the key to determining the presence of emeralds. Here is the data provided by the organizers so that contestants can find out the relationship between the plants and the treasure. Letâ€™s use your robot to collect plants and predict the location of the treasure!\n",
    "\n",
    "#### 4 start points in the competition:\n",
    "Treasure 1: [49, 4, -24]\n",
    "Treasure 2: [36, 4, -26]\n",
    "Treasure 3: [37, 4, -8]\n",
    "Treasure 4: [50, 4, -7]\n",
    "\n",
    "#### If you never learn classification before, you might be wondering How ??? Let's learn some background first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning and Unsupervised learning\n",
    "\n",
    "#### Supervised Learning\n",
    "\n",
    "In supervised learning, we use a set of labeled data to train our model. For example, in a classification task, if we want our model to be able to distinguish between dogs and cats in a set of photos, we can use a set of images and label them with cat or dog. After the training use this data, our model will be able to identify the new image and label it as a cat or a dog.\n",
    "\n",
    "#### Unsupervised Learning\n",
    "In unsupervised learning, we use unlabeled data to train the model. The model will analyze the data and find patterns in it. For example, if we train a model by a set of pictures of cat and dog, but without any labels, the model could divide photos into two categories and if we provide a new image of cat, the model will put the picture in the same category as the cat.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors (KNN)\n",
    "\n",
    "In this lesson we are going to learn a supervised learning algorithm called K-nearst neighbors. The idea of this algorithm is very simple, given an input point, find the nearest K neighbors to this point, and predict the type of the input point based on the type of the neighbor. For example, the red dot in the figure below is the input value, and we find the 3 nearest neighbors.\n",
    "<img src=\"resources/KNN.jpg\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean Distance:\n",
    "\n",
    "You might be wondering how do we calculate the distance between two data points, and the answer is Euclidean distance. Here is the Formula:\n",
    "<img src=\"resources/Euclidean.png\" width=300px>\n",
    "\n",
    "a and b in the formula are two points (vector) on the vector space, and we can easily visualize their distance in a two-dimensional coordinate system (see graph) \n",
    "\n",
    "<img src=\"resources/Distance graph.jpg\" width=600px>\n",
    "\n",
    "When vectors have more dimensions, it's hard to visualize on a graph. But the distance formula also works for higher dimensional vectors.\n",
    "\n",
    "So for implement KNN, the first step is calculate distance for all vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean distance Python implementation \n",
    "def Euclidean_dis(mine1,mine2):\n",
    "    diff=0\n",
    "    for x in range(len(mine1)):\n",
    "        diff+=(mine1[x]-mine2[x])**2\n",
    "    return diff**0.5\n",
    "#follow the formula to implement euclidean distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization:\n",
    "\n",
    "The next step is normalize our data, but why?\n",
    "\n",
    "Consider this example, if we want to determine whether a used car is worth buying based on some of attributes of the car, we can cansider the mileage of the car, the selling price, and the age of the car. However, the maximum age of the car is normally less than 15 years, but its price and mileage can exceed 100,000. There is a problem, when we calculate the distance between each vector, all attributes are treated equally, so if one car is ten years older than the other, we will cansider the 10 years difference have the same importance as 10 dollars difference on the price. This is completely ridiculous. So we need to normalize the data before we can calculate their distance.\n",
    "\n",
    "#### Min-max normalization:\n",
    "\n",
    "Min-max normalization is a commonly used normalization method. This is the formula:\n",
    "<img src=\"resources/Min_max.png\" width=300px>\n",
    "\n",
    "Let's implement Min-max normalization by Python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max normalization Python implementation \n",
    "def norm(x,lis):\n",
    "    mini=min(lis)\n",
    "    maxi=max(lis)\n",
    "    normalize=(x-mini)/(maxi-mini)\n",
    "    return normalize\n",
    "#follow the formula to implement Min-max normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN implementation\n",
    "\n",
    "Now we have the normalization function, let's calculate the distance between the input point and other points in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     oxeye_daisy  allium  blue_orchid  red_tulip  label\n",
      "0              5       9           10          7      0\n",
      "1              5       8            9          6      0\n",
      "2             11       3            4         10      1\n",
      "3              4       8            7          7      0\n",
      "4             10       3            5         10      1\n",
      "..           ...     ...          ...        ...    ...\n",
      "193            4       8            9          8      0\n",
      "194            9       4            2         10      1\n",
      "195            3       7            6          7      0\n",
      "196            6       9            8          8      0\n",
      "197            4       9            9          7      0\n",
      "\n",
      "[198 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# KNN implementation\n",
    "train_data=pd.read_csv(\"Lesson2_train_data.csv\")\n",
    "val_data=pd.read_csv(\"Lesson2_val_data.csv\")\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000038580172492, 0], [0.8788008189087495, 0], [1.097461583007751, 1]]\n"
     ]
    }
   ],
   "source": [
    "t_daisy=train_data['oxeye_daisy']\n",
    "t_allium=train_data['allium']\n",
    "t_orchid=train_data['blue_orchid']\n",
    "t_tulip=train_data['red_tulip']\n",
    "t_label=train_data['label']\n",
    "\n",
    "def normlist(lis):\n",
    "    normlist=[]\n",
    "    for x in lis:\n",
    "        normlist.append(norm(x,lis))\n",
    "    return normlist\n",
    "\n",
    "def normsample(x):\n",
    "    x1=norm(x[0],t_daisy)\n",
    "    x2=norm(x[1],t_allium)\n",
    "    x3=norm(x[2],t_orchid)\n",
    "    x4=norm(x[3],t_tulip)\n",
    "    lis=[x1,x2,x3,x4]\n",
    "    return lis\n",
    "\n",
    "nt_daisy=normlist(t_daisy)\n",
    "nt_allium=normlist(t_allium)\n",
    "nt_orchid=normlist(t_orchid)\n",
    "nt_tulip=normlist(t_tulip)\n",
    "\n",
    "train_dataset=list(zip(nt_daisy,nt_allium,nt_orchid,nt_tulip))\n",
    "\n",
    "count=[]\n",
    "sample=[3,6,1,7]\n",
    "for x in range(len(train_dataset)):\n",
    "        count.append([Euclidean_dis(normsample(sample),train_dataset[x]),t_label[x]])\n",
    "print(count[0:3])       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction\n",
    "\n",
    "Now we have the distance between all points, let's find top k neighbors and make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Top K neighbors\n",
    "def KNN(sample,t_dataset,k,t_label):\n",
    "    count=[]\n",
    "    #normsample=normsample(sample)\n",
    "    for x in range(len(t_dataset)):\n",
    "        count.append([Euclidean_dis(normsample(sample),t_dataset[x]),t_label[x]])\n",
    "        \n",
    "    count.sort()\n",
    "    kn=count[:k]\n",
    "    predict=0\n",
    "    for x in kn:\n",
    "        predict+=x[1]\n",
    "\n",
    "    if predict/k>0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "print(KNN([3,6,1,7],train_dataset,3,t_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the accuracy of your model\n",
    "\n",
    "Generally, we will divide our data into two groups in a ratio of 1:9 or 2:8 as the training set and validation set. We will use training set to train our ML model and use validation set to test the performance of the model. Now let's use the validation set that we provided to evaluate the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "v_daisy=val_data['oxeye_daisy']\n",
    "v_allium=val_data['allium']\n",
    "v_orchid=val_data['blue_orchid']\n",
    "v_tulip=val_data['red_tulip']\n",
    "v_label=val_data['label']\n",
    "\n",
    "\n",
    "val_dataset=list(zip(v_daisy,v_allium,v_orchid,v_tulip))\n",
    "\n",
    "val_count=0\n",
    "for x in range (len(val_dataset)):\n",
    "    if KNN(val_dataset[x],train_dataset,3,t_label)==v_label[x]:\n",
    "        val_count+=1\n",
    "\n",
    "        \n",
    "print(val_count/len(v_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program your robot\n",
    "\n",
    "Now we have created a KNN classification model, let's program your robot to collect the plants and predict which area has emeralds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#program your robot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
